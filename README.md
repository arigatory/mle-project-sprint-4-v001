# Подготовка виртуальной машины

## Склонируйте репозиторий

Склонируйте репозиторий проекта:

```
git clone https://github.com/arigatory/mle-project-sprint-4-v001.git
```

## Активируйте виртуальное окружение

Используйте то же самое виртуальное окружение, что и созданное для работы с уроками. Если его не существует, то его следует создать.

Создать новое виртуальное окружение можно командой:

```
python3 -m venv env_recsys_start
```

После его инициализации следующей командой

```
. env_recsys_start/bin/activate
```

установите в него необходимые Python-пакеты следующей командой

```
pip install -r requirements.txt
```

### Скачайте файлы с данными

Для начала работы понадобится три файла с данными:
- [tracks.parquet](https://storage.yandexcloud.net/mle-data/ym/tracks.parquet)
- [catalog_names.parquet](https://storage.yandexcloud.net/mle-data/ym/catalog_names.parquet)
- [interactions.parquet](https://storage.yandexcloud.net/mle-data/ym/interactions.parquet)
 
Скачайте их в директорию локального репозитория. Для удобства вы можете воспользоваться командой wget:

```
wget https://storage.yandexcloud.net/mle-data/ym/tracks.parquet

wget https://storage.yandexcloud.net/mle-data/ym/catalog_names.parquet

wget https://storage.yandexcloud.net/mle-data/ym/interactions.parquet
```

## Запустите Jupyter Lab

Запустите Jupyter Lab в командной строке

```
jupyter lab --ip=0.0.0.0 --no-browser
```

# Проект системы рекомендаций музыкальных треков

Этот проект реализует полноценную систему рекомендаций для музыкальных треков, включающую:
- Анализ данных и подготовку (EDA)
- Несколько алгоритмов рекомендаций (популярные, персональные ALS, item-to-item)
- Ранжирующую модель с машинным обучением
- Комплексную оценку качества рекомендаций

## Структура проекта

```
├── recommendations.ipynb          # Основной notebook с реализацией всех этапов
├── requirements.txt              # Зависимости Python
├── tracks.parquet               # Данные о треках (скачиваются отдельно)
├── catalog_names.parquet        # Каталог названий (скачиваются отдельно)
├── interactions.parquet         # Данные взаимодействий (скачиваются отдельно)
└── recsys/                      # Директория для результатов
    ├── data/                    # Обработанные данные (items.parquet, events.parquet)
    └── recommendations/         # Файлы рекомендаций (генерируются автоматически)
```

# Расчёт рекомендаций

## Этапы выполнения проекта

### Этап 1: Исследовательский анализ данных (EDA)
- Загрузка и изучение структуры данных
- Анализ распределений и основных статистик
- Выявление паттернов в поведении пользователей

### Этап 2: Подготовка данных
- Очистка и предобработка данных
- Создание признаков для моделирования
- Сохранение подготовленных данных в `recsys/data/`

### Этап 3: Построение системы рекомендаций
- **Популярные рекомендации**: Baseline на основе глобальной популярности треков
- **Персональные ALS рекомендации**: Коллаборативная фильтрация с матричной факторизацией
- **Item-to-item рекомендации**: Рекомендации на основе похожести треков
- **Ранжирующая модель**: Random Forest с множественными признаками
- **Оценка качества**: Метрики Recall, Precision, Coverage, Novelty

## Запуск проекта

Откройте файл `recommendations.ipynb` в Jupyter Lab и выполните все ячейки последовательно:

```bash
jupyter lab recommendations.ipynb
```

### Результаты выполнения

После выполнения всех ячеек будут созданы:

1. **Обработанные данные** в `recsys/data/`:
   - `items.parquet` - информация о треках с признаками
   - `events.parquet` - взаимодействия пользователей с временными метками

2. **Файлы рекомендаций** в `recsys/recommendations/`:
   - `top_popular.parquet` - популярные рекомендации
   - `personal_als.parquet` - персональные ALS рекомендации
   - `similar.parquet` - item-to-item рекомендации
   - `recommendations.parquet` - финальные ранжированные рекомендации

3. **Метрики качества** для всех алгоритмов:
   - Recall@100 - полнота рекомендаций
   - Precision@100 - точность рекомендаций
   - Coverage - покрытие каталога
   - Novelty - новизна рекомендаций

## Технические детали

### Алгоритмы рекомендаций:

1. **Top Popular**: Взвешенная популярность (70% прослушивания + 30% уникальные пользователи)
2. **ALS (Alternating Least Squares)**: 50 факторов, 10 итераций, L2 регуляризация
3. **Item-to-Item**: Косинусное сходство на основе user-item матрицы
4. **Ranking Model**: Random Forest с признаками:
   - Популярность трека
   - Активность пользователя
   - Обратный ранг базового алгоритма
   - Источник рекомендации
   - Совпадение жанровых предпочтений

### Оценка качества:
- **Train/Test split**: Данные до 16 декабря 2022 / после 16 декабря 2022
- **Метрики**: Recall@100, Precision@100, Coverage, Novelty
- **Baseline сравнение**: Все алгоритмы сравниваются с популярными рекомендациями

## Требования к ресурсам

- **RAM**: Минимум 8GB (рекомендуется 16GB)
- **Время выполнения**: 30-60 минут (в зависимости от железа)
- **Дисковое пространство**: ~3GB для данных и результатов

## Troubleshooting

**При нехватке памяти:**
- Уменьшите `batch_size` в ячейках генерации рекомендаций
- Закройте другие приложения
- Рассмотрите использование более мощной машины

**При ошибках с зависимостями:**
```bash
pip install --upgrade pip
pip install -r requirements.txt --force-reinstall
```
